#LyX 1.6.7 created this file. For more info see http://www.lyx.org/
\lyxformat 345
\begin_document
\begin_header
\textclass article
\use_default_options true
\language english
\inputencoding auto
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry true
\use_amsmath 1
\use_esint 1
\cite_engine basic
\use_bibtopic false
\paperorientation portrait
\leftmargin 1in
\topmargin 1in
\rightmargin 1in
\bottommargin 1in
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\defskip medskip
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\author "" 
\author "" 
\end_header

\begin_body

\begin_layout Title
The Ames Multiple-View Pipeline
\end_layout

\begin_layout Author
Kyle D.
 Husmann
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
kyle.husmann@gmail.com
\end_layout

\end_inset


\begin_inset Newline newline
\end_inset


\shape italic
\size normal
California Polytechnic State University, San Luis Obispo, CA, USA
\shape default
\size default

\begin_inset Newline newline
\end_inset


\begin_inset Newline newline
\end_inset

Taemin Kim
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
taemin.kim@nasa.gov
\end_layout

\end_inset

 
\begin_inset Newline newline
\end_inset


\shape italic
\size normal
Intelligent Robotics Group, NASA Ames Research Center, CA, USA
\end_layout

\begin_layout Date
August 27, 2010
\end_layout

\begin_layout Abstract
The Ames Stereo Pipeline (ASP) is an ongoing effort by the Intelligent Robotics
 Group at NASA Ames Research Center to provide planetary scientists with
 the tools to create digital elevation models (DEMs) from orbital imagery.
 While the ASP produces excellent results, it has a fundamental limitation
 that restricts its quality and robustness: since it is based on stereo
 reconstruction algorithms, it can take only two views into account at a
 time.
 To improve upon the ASP we propose the Ames Multiple-View Pipeline (AMVP)
 that will model the entire image formation process and find the optimal
 height for each DEM post given every available orbital image.
 Complex terrain and reflectance models are simplified by assuming planar
 terrain and a linear reflectance model on a small patch around a given
 DEM post.
 In addition to being capable of multiple view reconstruction, the AMVP
 will solve many shortcomings of the ASP in the areas of software design,
 user interface, and performance.
 With the AMVP, we hope to create the next-generation software suite for
 performing the large-scale multiple-view DEM reconstruction from orbital
 imagery.
\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
For years, the Intelligent Robotics Group (IRG) at NASA Ames Research Center
 has been studying stereo reconstruction technologies for ground based planetary
 exploration, equipping rovers with stereo camera rigs for avoiding obstacles
 and mapping their surroundings.
 Over the past couple of years this research has expanded to include the
 stereo processing of orbital imagery to recover the topography of planetary
 bodies such as the moon and Mars.
 
\end_layout

\begin_layout Standard
Traditionally, recovering the topography of planetary surfaces has been
 a long and arduous process, taking many days and resources to create a
 single digital elevation model (DEM).
 Human operators would work at stereogrammetry stations, manually matching
 points between images of the planetary surface to triangulate their location.
 However, these methods are much too slow and expensive to process the onslaught
 of data being generated by recent missions such as the Lunar Reconnaissance
 Orbiter (LRO) and Mars Reconnaissance Orbiter (MRO).
 Clearly, an automated system for creating DEMs is required.
\end_layout

\begin_layout Standard
The Ames Stereo Pipeline (ASP), was developed by the IRG with the aim to
 satisfy this need for the automation of the DEM construction process.
 Aside from some basic settings that are needed at the beginning, DEMs can
 be created with the ASP without any human interaction.
 
\end_layout

\begin_layout Standard
Although the ASP satisfies the current and short-term needs of the IRG,
 it is time to begin developing the next generation software suite for the
 automated generation and processing of large-scale DEM mosaics.
 Specifically, we are interested in going beyond the usual two views used
 in the stereo reconstruction process and generalizing the process to use
 all views available in the scene being reconstructed.
 By moving to a multiple-view stereo approach, we will be able to increase
 the accuracy of the DEMs while at the same time robustly rejecting outliers
 in the source imagery.
 Simply extending the ASP with these features will not be possible because
 it has been designed from the beginning to handle only two views.
 For this reason, we propose the creation of a new project: the Ames Multiple-Vi
ew Pipeline (AMVP).
\end_layout

\begin_layout Standard
In addition to using a novel multiple view stereo algorithm specifically
 designed for the construction of high-accuracy DEMs, the AMVP will incorporate
 many 
\begin_inset Quotes eld
\end_inset

lessons learned
\begin_inset Quotes erd
\end_inset

 from many of the shortcomings of the ASP, resulting in a system that runs
 faster, is more automated, is easier to use, and produces superior results.
\end_layout

\begin_layout Standard
This paper will begin with a brief description of the structure of the ASP
 followed by a discussion of its shortcomings and how the AMVP will address
 them.
 Then, a design for the proposed AMVP will be outlined along with discussion
 as to the time-frame expected for the AMVP's development.
 
\end_layout

\begin_layout Section
The Ames Stereo Pipeline
\end_layout

\begin_layout Standard
The ASP was first officially released in late October 2009 and is still
 the only free, open-source, automated stereogrammetry software suite available
 to the public.
 In this section, we give an overview of its internal workings and then
 describe the ways in which the AMVP will be able to improve upon the ASP's
 design.
\end_layout

\begin_layout Subsection
Pipeline Overview
\end_layout

\begin_layout Standard
The flow of data through the ASP can be separated in to discrete stages
 as depicted in figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:asp-flowchart"

\end_inset

.
 Input data is shown as red boxes, output data is shown as green boxes,
 and processing stages are shown in blue boxes.
 The faded blue boxes around the processing stages represent the programs
 in the ASP that they belong to.
 The following describes the flow of data through the Bundle Adjustment,
 Registration / Preprocessing, Disparity Map Initialization, Sub-Pixel Refinemen
t, Outlier Rejection / Hole Filling, Triangulation, and Mesh / DEM Generation
 stages.
 
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename asp_flowchart.tiff
	lyxscale 30
	width 10cm

\end_inset


\begin_inset Caption

\begin_layout Plain Layout
Flow of data through the ASP 
\begin_inset CommandInset citation
LatexCommand cite
key "asp-manual2009"

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "fig:asp-flowchart"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Bundle Adjustment
\end_layout

\begin_layout Standard
Before any dense stereogrammetry takes place, the estimated position and
 orientation of the camera used to take each orbital image in the dataset
 must be refined to properly triangulate the DEM.
 When this step is skipped, errors in measurements contained in the satellite
 telemetry data can cause DEMs to not line up when they are placed in a
 mosaic (figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:bundle-adjust"

\end_inset

).
 To ensure DEMs line up as best as possible, a processes known as “bundle
 adjustment” is performed.
 First, numerous points across all source imagery are matched using a standard
 interest point detection algorithm such as SURF 
\begin_inset CommandInset citation
LatexCommand cite
key "surf-bay2008"

\end_inset

 (outliers are rejected with RANSAC 
\begin_inset CommandInset citation
LatexCommand cite
key "ransac-fischler1981"

\end_inset

).
 Then, camera parameters are iteratively adjusted until the errors between
 the projections of the matching points (called tie-points) into other camera
 frames are minimized.
 Often, a couple points chosen by hand called “ground control points” are
 used to register the DEMs to another dataset.
 
\begin_inset Wrap figure
lines 0
placement O
overhang 0in
width "50col%"
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename dem_no_bundle_adjust.tiff
	lyxscale 30
	width 6cm

\end_inset


\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename dem_bundle_adjust.tiff
	lyxscale 30
	width 6cm

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
A colorized DEM mosaic made from Apollo 15 Orbit 33 imagery.
 Top: Before bundle adjustment, large discontinuities are clearly visible
 between DEMs.
 Bottom: Bundle adjustment minimizes these discontinuities
\begin_inset CommandInset label
LatexCommand label
name "fig:bundle-adjust"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Registration / Preprocessing
\end_layout

\begin_layout Standard
After the bundle adjustment stage been completed, the registration stage
 aligns the two source images, if possible.
 If the source imagery was captured with a camera that can be modeled by
 the pinhole camera model (like imagery from the Apollo missions), the images
 can be warped so that they share a common image plane (also known as epipolar
 alignment).
 This is done so that corresponding features in both images can be quickly
 found by simply searching across scan lines.
 Imagery that has been captured using line scan cameras (like imagery captured
 by the HiRISE camera) is usually aligned by map projecting them using ISIS.
 Finally, the preprocessing stage filters the images to remove noise and
 normalize against illumination changes.
 Typically, a LOG (Laplacian Of Gaussian) filter is applied to accomplish
 this.
\end_layout

\begin_layout Subsubsection
Disparity Map Initialization
\end_layout

\begin_layout Standard
After the source images have been prepared, the Disparity Map Initialization
 stage matches pixels between the images.
 In this stage lies the central problem of stereogrammetry, the correspondence
 problem: for each pixel in the left image, a pixel in the right image must
 be found that represents the same point on the surface being imaged.
 Only after this is determined can the 3D location of the point can be recovered
 (see Triangulation, below).
 The offset required for a particular pixel in the left image to find its
 matching pixel in the right image is known as 
\emph on
disparity
\emph default
.
 The image that stores the disparity offsets for each pixel in the left
 image is called the disparity map.
 The object of the Disparity Map Initialization stage is to quickly create
 a rough estimate of the disparity map that will be later refined to sub-pixel
 accuracy in the subsequent Sub-Pixel Refinement stage.
\end_layout

\begin_layout Standard
The ASP uses a template matching approach for this step.
 Given a pixel in the left image, to find its corresponding pixel in the
 right image, a small window around the left pixel is taken and compared
 to areas of the right image as depicted in figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:template-matching"

\end_inset

.
 Usually, normalized cross correlation is used to define similarity.
 The integer offset that finds the most similar patch of pixels in the right
 image is recorded as the disparity for that left pixel.
 In the ASP, the process of searching through each possible disparity is
 optimized by using a box filter along with adaptive subregions in a pyramid-bas
ed approach 
\begin_inset CommandInset citation
LatexCommand cite
key "subregion-sun2002"

\end_inset

.
 
\begin_inset Wrap figure
lines 0
placement O
overhang 0in
width "50col%"
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename template_matching.tiff
	lyxscale 20
	width 7cm

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Determining disparity using a template matching approach 
\begin_inset CommandInset label
LatexCommand label
name "fig:template-matching"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Sub-Pixel Refinement
\end_layout

\begin_layout Standard
This next stage refines the integer disparity estimates found in the disparity
 map initialization step to sub-pixel accuracy.
 Two algorithms are available: parabola fitting and a high quality technique
 developed at Ames called Bayes EM weighted adaptive window correlation.
 A visual comparison of results produced by these algorithms can be seen
 in figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:subpixel-modes"

\end_inset

.
 
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename subpixel_mode_top.tiff
	lyxscale 30
	width 12cm

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset VSpace 0.07cm
\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename subpixel_mode_bottom.tiff
	lyxscale 30
	width 12cm

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Left: source image (top) and right source image (bottom).
 Center: Mesh (top) and hillshade (bottom) produced by the parabola sub-pixel
 mode.
 Right: Mesh (top) and hillshade (bottom) produced by the Bayes EM sub-pixel
 mode
\begin_inset CommandInset label
LatexCommand label
name "fig:subpixel-modes"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Parabola fitting is a simple process: for a given pixel, the matching scores
 of the eight surrounding pixels are calculated and then fitted to a paraboloid.
 The minimum of this surface is used as the sub-pixel disparity.
 Although this method is fast, it exhibits a problem known as “pixel locking”:
 results tend to fall near the initial integer estimates and create stair-step
 artifacts in the resulting mesh.
\end_layout

\begin_layout Standard
The Bayes EM weight adaptive window correlation algorithm was developed
 at Ames to obtain very high quality sub-pixel results that are robust to
 image noise.
 The algorithm uses template windows that are be warped with affine transformati
ons to accommodate perspective changes.
 The parameters for these template windows are treated as random variables
 in an expectation maximization (EM) framework with a Gaussian mixture model.
 For an in-depth description and discussion of this technique, see 
\begin_inset CommandInset citation
LatexCommand cite
key "bayessub-nefian2009"

\end_inset

.
\end_layout

\begin_layout Subsubsection
Outlier Rejection / Hole Filling
\end_layout

\begin_layout Standard
After the sub-pixel disparity map is generated, it is filtered to remove
 outliers (defined by large discontinuities in the disparity map) and fill
 holes.
 The holes are identified and filled using an inpainting method described
 in 
\begin_inset CommandInset citation
LatexCommand cite
key "inpaint-bert2000"

\end_inset

.
\end_layout

\begin_layout Subsubsection
Triangulation
\end_layout

\begin_layout Standard
After the sub-pixel disparity map has been completed, the camera models
 from the two source images are used to determine the 3D locations corresponding
 to each point in the source imagery.
 The 3D location for a given pixel the left image and is corresponding pixel
 in the right image (as defined by the disparity map) is found by intersecting
 the two rays that pass through each pixel and their respective camera center.
 The final product of this stage is a point cloud: XYZ locations that define
 the surface of the planetary surface being reconstructed.
\end_layout

\begin_layout Subsubsection
Mesh / DEM Generation
\end_layout

\begin_layout Standard
The last step in the process is to take the point cloud generated by the
 triangulation step and build a mesh to interpolate between the points.
 The mesh can either be viewed with a 3D viewer or be sampled at regular
 intervals to create a DEM.
 After many of these DEMs are created (one from each orbital image pair),
 they can be stitched together to form a mosaic.
\end_layout

\begin_layout Subsection
Shortcomings of the ASP
\end_layout

\begin_layout Standard
While the ASP produces great results, it has many shortcomings that we hope
 to address with the development of the AMVP.
 We divide these shortcomings into three main categories: software design,
 user interface, and performance / scalability.
\end_layout

\begin_layout Subsubsection
Software Design
\end_layout

\begin_layout Standard
As stated before, the ASP was designed from the beginning to only handle
 two views.
 To generalize the software infrastructure so that multiple views are accepted
 requires a complete overhaul, which is why we are proposing the AMVP.
\end_layout

\begin_layout Standard
Additionally, the ASP is difficult to interrupt.
 While the pipeline process can be restarted from any stage, if a stage
 is interrupted it can only be restarted from the beginning.
 By using the Vision Workbench plate file system 
\begin_inset CommandInset citation
LatexCommand cite
key "asp-manual2009"

\end_inset

, stages will be able to be interrupted and restarted with little consequence.
\end_layout

\begin_layout Subsubsection
User Interface
\end_layout

\begin_layout Standard
Although very few settings are needed to produce a DEM from the source imagery,
 some settings like the 
\begin_inset Quotes eld
\end_inset

search range
\begin_inset Quotes erd
\end_inset

 are not intuitive and can create large performance and quality problems
 if set incorrectly.
 As a part of the AMVP, we would develop ways of automatically detecting
 these settings.
\end_layout

\begin_layout Subsubsection
Performance / Scalability
\end_layout

\begin_layout Standard
In order to create a large-scale DEM mosaic with the ASP, many DEMs must
 be produced from orbital imagery and then later stitched together to form
 a mosaic.
 This creates one more step in the DEM mosaic creation process as well as
 increasing the need for temporary storage.
 By using the plate file system in the AMVP we will be able to create giant
 mosaics directly in the pipeline process, making the system more automated
 as well as reducing the memory requirements.
\end_layout

\begin_layout Standard
Finally, because ISIS is not thread-safe, when ISIS camera models are used
 in the ASP they force the triangulation step to be single threaded.
 This is a huge performance hit and hurts the scalability of the whole system.
 We aim to solve this by converting the ISIS camera models into ones natively
 supported by our pipeline, allowing camera model calculations to be multi-threa
ded as they should be.
 While this feature could (and should!) be implemented into the ASP, it
 will definitely be included in the AMVP.
\end_layout

\begin_layout Section
The Ames Multiple-View Pipeline
\end_layout

\begin_layout Standard
Here we propose our concept for the AMVP.
 As stated before, unlike the ASP the AMVP would be designed from the ground
 up to handle multiple views.
 In addition, instead of correlating many image pairs and later having to
 mosaic them into the final DEM, the AMVP will completely remove this step
 by working in map projected space.
\end_layout

\begin_layout Subsection
Pipeline Overview
\end_layout

\begin_layout Standard
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:amvp-flowchart"

\end_inset

 shows how data will flow through the AMVP.
 The three stages are as follows: bundle adjustment, disparity map initializatio
n and multiple-view refinement.
 While some of these stages are similar to ones found in the ASP, the fundamenta
l difference is that the pipeline will ingest the entirety of the orbital
 imagery available and then build a giant DEM tile by tile, rather than
 creating many smaller DEMs from stereo pairs and then having to mosaic
 them in a separate step.
\end_layout

\begin_layout Standard
The AMVP has a much simpler data-flow model than the ASP.
 The Registration / Preprocessing is no longer needed as the AMVP is able
 to operate directly on the source imagery.
 The Disparity Map Initialization and Sub-Pixel Refinement stages are replaced
 by Multiple-View Initialization and Multiple-View Refinement stages.
 And finally, the Mesh / DEM Generation stage is no longer needed, since
 the optimal location of every DEM post is solved for in the Multiple-View
 Refinement stage.
\begin_inset Wrap figure
lines 0
placement O
overhang 0in
width "50col%"
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename amvp_flowchart.pdf
	lyxscale 30
	height 7cm

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Flow of data through the AMVP
\begin_inset CommandInset label
LatexCommand label
name "fig:amvp-flowchart"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Bundle Adjustment
\end_layout

\begin_layout Standard
Like the corresponding stage in the ASP, the Bundle Adjustment stage in
 the AMVP refines the estimated position and orientation of the camera used
 to take each orbital image in the dataset.
 As in the ASP's Bundle Adjustment stage (described above), tie-points are
 found using the source imagery.
 These points will be needed in the subsequent Multiple-View Initialization
 stage, which is itself initialized by tie-points.
\end_layout

\begin_layout Subsubsection
Multiple-View Initialization
\end_layout

\begin_layout Standard
The purpose of this stage is to create a low-resolution DEM that will be
 used to seed the Multiple-View Refinement stage.
 The algorithm that will be used here is still in heavy development.
 It works by assuming the small patch around a given DEM post is locally
 planar with a linear reflectance model.
 The parameters for this plane (surface normal and height), as well as the
 parameters for the linear reflectance model are solved in an expectation
 maximization (EM) framework, designed to minimize the differences between
 the orbital images projected onto the patch in question.
 We plan to use tie-points found by the Bundle Adjustment stage as an initial
 guess for the heights of these patches.
 We have already created a small scale proof of concept that shows the promising
 direction of this research, and expect to have a final version of the algorithm
 ready in the next six months (see Development Time Line, below).
\end_layout

\begin_layout Standard
It is important to note here the power of our approach compared to the one
 taken by the ASP.
 The ASP solves for the disparity between two orbital images, uses that
 disparity to triangulate the corresponding 3D point, builds a mesh and
 finally interpolates on that mesh to find the height of a particular DEM
 post.
 In contrast, our algorithm directly finds the 
\emph on
optimal
\emph default
 height for a particular DEM post given 
\emph on
all
\emph default
 the orbital imagery that overlaps on that point, no mesh interpolation
 (or averaging between DEMs generated with different stereo pairs) required.
\end_layout

\begin_layout Subsubsection
Multiple-View Refinement
\end_layout

\begin_layout Standard
After the low-resolution DEM is obtained, an interpolated version of the
 DEM is refined at the highest possible resolution (as dictated by the source
 imagery) in the Multiple-View Refinement stage.
 To boost the speed of this stage, a variant of the algorithm used in the
 Multiple-View Initialization stage that is optimized to operate on image
 blocks rather than independent pixels will be used.
\end_layout

\begin_layout Subsection
Development Time Line
\end_layout

\begin_layout Standard
We expect that the implementation of the AMVP will take about a year and
 a half: six months to finish the multiple-view reconstruction proof of
 concept, and another year to create the large-scale implementation.
 Taemin will be focusing primarily on the theoretical side of the project,
 working to ensure the optimization algorithms work as efficiently as possible
 and finding ways to model and test our results.
 Kyle will work primarily on the implementation and software design side,
 creating the software infrastructure necessary to accomplish our goals.
\end_layout

\begin_layout Subsubsection
Multiple-View Reconstruction Proof of Concept
\end_layout

\begin_layout Standard
The algorithms used in the Multiple-View Initialization and Multiple-View
 Refinement stages are still under heavy development.
 For the past ten weeks, we have have successfully built a small-scale proof
 of concept.
 There is still significant work left here: even though these early efforts
 our promising, we estimate it will take another six months of development
 to put the algorithm in a scalable form and to properly test and verify
 its results.
\end_layout

\begin_layout Standard
I, (Kyle speaking), plan to continue working on this proof of concept during
 the school year and make it into my senior project for my studies at Cal
 Poly.
 This means I will finish this proof of concept, along with documentation
 and a paper evaluating its performance before I graduate in March 2011.
\end_layout

\begin_layout Subsubsection
Large-Scale Implementation
\end_layout

\begin_layout Standard
After the multiple-view reconstruction proof of concept is completed, we
 expect that the large-scale implementation of the AMVP will take about
 a year.
 There will be many technical challenges that will need to be solved in
 a scalable manner.
 While detecting overlap and edge cases are problems that are easy to solve
 in a small-scale environment, we need to find solutions that can be distributed
 across multiple threads, processes or machines.
 Furthermore, we will need to spend a significant amount of time designing
 the software infrastructure to be extensible and capable of supporting
 future research directions, like photometric refinement.
 Finally, as in any large software development project, there will be much
 time devoted to evaluating the implementation's performance and generating
 automated tests.
\end_layout

\begin_layout Standard
Since I, (Kyle speaking again), am not yet sure what my post-graduation
 plans are, I may or may not be available to work on the final implementation
 of the AMVP.
 As we near my graduation in March 2011, we can begin talking about my involveme
nt in this project as well as begin to create milestones for its implementation.
\end_layout

\begin_layout Section
Conclusion
\end_layout

\begin_layout Standard
The development of the AMVP will be an exciting next step in the field of
 automated DEM construction processes.
 We expect that the final version will run at least as fast as the ASP,
 but provide better results and be much easier to use.
 Furthermore, with a good software infrastructure, we will be able to use
 it to further other areas of research like the photometric refinement of
 DEMs.
 In the meantime, we will focus on developing and characterizing the core
 multiple-view algorithm while we continue to build and refine the software
 technologies required for its large-scale implementation.
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "../amvp"
options "plain"

\end_inset


\end_layout

\end_body
\end_document
